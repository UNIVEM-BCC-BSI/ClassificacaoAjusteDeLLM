{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dlXKhvIvbres"
      },
      "outputs": [],
      "source": [
        "# Importando as principais bibliotecas\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKiBfxZAEvT3",
        "outputId": "277701c3-a6c3-4a97-f114-ae584f4abbc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/'\n",
        "\n",
        "# Carregar dados\n",
        "for fname in ['train.csv','test.csv','sample_submission.csv']:\n",
        "    if not os.path.exists(os.path.join(PATH, fname)):\n",
        "        print(f'AVISO: {fname} nao encontrado no diretorio: {PATH}')\n",
        "\n",
        "train = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(PATH, 'test.csv'))\n",
        "sample_sub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))\n",
        "\n",
        "print('Shapes:')\n",
        "print('train', train.shape)\n",
        "print('test', test.shape)\n",
        "print('sample_submission', sample_sub.shape)\n",
        "\n",
        "# mostrar primeiras linhas para inspeção\n",
        "train.head()"
      ],
      "metadata": {
        "id": "bhQFqhQnFeMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "065c4e90-5b85-432e-bd8c-16befa2211f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 9 fields in line 972, saw 10\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4085662008.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'AVISO: {fname} nao encontrado no diretorio: {PATH}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msample_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 9 fields in line 972, saw 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_label(row):\n",
        "    if row.get('winner_model_a',0) == 1:\n",
        "        return 'a'\n",
        "    if row.get('winner_model_b',0) == 1:\n",
        "        return 'b'\n",
        "    return 'tie'\n",
        "\n",
        "train['label'] = train.apply(make_label, axis=1)\n",
        "train['label'].value_counts()"
      ],
      "metadata": {
        "id": "p324MjEYb6Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_basic_features(df):\n",
        "    df = df.copy()\n",
        "    df['prompt_len'] = df['prompt'].astype(str).apply(len)\n",
        "    df['prompt_words'] = df['prompt'].astype(str).apply(lambda s: len(s.split()))\n",
        "    df['resp_a_len'] = df['response_a'].astype(str).apply(len)\n",
        "    df['resp_b_len'] = df['response_b'].astype(str).apply(len)\n",
        "    df['resp_a_words'] = df['response_a'].astype(str).apply(lambda s: len(s.split()))\n",
        "    df['resp_b_words'] = df['response_b'].astype(str).apply(lambda s: len(s.split()))\n",
        "    df['len_diff_ab'] = df['resp_a_len'] - df['resp_b_len']\n",
        "    df['abs_len_diff_ab'] = df['len_diff_ab'].abs()\n",
        "    return df\n",
        "\n",
        "train_f = add_basic_features(train)\n",
        "test_f = add_basic_features(test)\n",
        "train_f[['prompt_len','resp_a_len','resp_b_len','len_diff_ab']].head()"
      ],
      "metadata": {
        "id": "L3exwJ7kb8sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF + TruncatedSVD (prompt e respostas concatenadas)\n",
        "n_svd = 50\n",
        "tfidf_prompt = TfidfVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
        "tfidf_resp = TfidfVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
        "\n",
        "tfidf_prompt.fit(train_f['prompt'].astype(str).tolist())\n",
        "tfidf_resp.fit((train_f['response_a'].astype(str) + ' ' + train_f['response_b'].astype(str)).tolist())\n",
        "\n",
        "svd_prompt = TruncatedSVD(n_components=n_svd, random_state=42)\n",
        "svd_resp = TruncatedSVD(n_components=n_svd, random_state=42)\n",
        "\n",
        "prompt_tfidf_train = tfidf_prompt.transform(train_f['prompt'].astype(str))\n",
        "resp_tfidf_train = tfidf_resp.transform((train_f['response_a'].astype(str) + ' ' + train_f['response_b'].astype(str)))\n",
        "svd_prompt.fit(prompt_tfidf_train)\n",
        "svd_resp.fit(resp_tfidf_train)\n",
        "prompt_svd_train = svd_prompt.transform(prompt_tfidf_train)\n",
        "resp_svd_train = svd_resp.transform(resp_tfidf_train)\n",
        "\n",
        "prompt_tfidf_test = tfidf_prompt.transform(test_f['prompt'].astype(str))\n",
        "resp_tfidf_test = tfidf_resp.transform((test_f['response_a'].astype(str) + ' ' + test_f['response_b'].astype(str)))\n",
        "prompt_svd_test = svd_prompt.transform(prompt_tfidf_test)\n",
        "resp_svd_test = svd_resp.transform(resp_tfidf_test)\n",
        "\n",
        "print('SVD shapes:', prompt_svd_train.shape, resp_svd_train.shape)"
      ],
      "metadata": {
        "id": "njpjqQj_b_WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar features numéricas e vetoriais\n",
        "num_cols = ['prompt_len','prompt_words','resp_a_len','resp_b_len','resp_a_words','resp_b_words','len_diff_ab','abs_len_diff_ab']\n",
        "X_num_train = train_f[num_cols].values\n",
        "X_num_test = test_f[num_cols].values\n",
        "X_train = np.hstack([X_num_train, prompt_svd_train, resp_svd_train])\n",
        "X_test = np.hstack([X_num_test, prompt_svd_test, resp_svd_test])\n",
        "print('X_train shape', X_train.shape)\n",
        "print('X_test shape', X_test.shape)"
      ],
      "metadata": {
        "id": "g5OdjVGADWQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Regressão Logística"
      ],
      "metadata": {
        "id": "SbJdGlgsDZEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar rótulos e divisão\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train_f['label'].values)\n",
        "print('Classes:', le.classes_)\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Treinar LogisticRegression multinomial (solução simples e rápida)\n",
        "lr = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs')\n",
        "lr.fit(X_tr, y_tr)\n",
        "\n",
        "# Prever probabilidades e calcular log loss\n",
        "proba_val_lr = lr.predict_proba(X_val)\n",
        "ll_lr = log_loss(y_val, proba_val_lr)\n",
        "y_pred_lr = lr.predict(X_val)\n",
        "print('LogisticRegression - Validation log loss:', ll_lr)\n",
        "print('Accuracy (val) (LR):', accuracy_score(y_val, y_pred_lr))\n",
        "print(classification_report(y_val, y_pred_lr, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "dWPw06nXDfVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_full = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs')\n",
        "lr_full.fit(X_train, y)\n",
        "\n",
        "proba_test_lr = lr_full.predict_proba(X_test)\n",
        "\n",
        "df_proba = pd.DataFrame(proba_test_lr, columns=[f'prob_{c}' for c in le.classes_])\n",
        "map_cols = {'a':'winner_model_a','b':'winner_model_b','tie':'winner_model_tie'}\n",
        "sub = pd.DataFrame()\n",
        "sub['id'] = test['id']\n",
        "for cls in le.classes_:\n",
        "    sub[map_cols[cls]] = df_proba[f'prob_{cls}'].values\n",
        "sums = sub[['winner_model_a','winner_model_b','winner_model_tie']].sum(axis=1)\n",
        "sub[['winner_model_a','winner_model_b','winner_model_tie']] = sub[['winner_model_a','winner_model_b','winner_model_tie']].div(sums, axis=0)\n",
        "print('submission_logistic.csv salvo com shape', sub.shape)\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "bjKh5I8yDhvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizações para slides: matriz de confusão, histogramas de probabilidade, distribuição de rótulos no teste\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "conf = pd.crosstab(le.inverse_transform(y_val), le.inverse_transform(y_pred_lr))\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(conf, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matriz de confusão (Logistic Regression - validação)')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xlabel('Previsto')\n",
        "plt.tight_layout()\n",
        "os.makedirs('figs_for_slides', exist_ok=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jEf0C4htDkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogramas de probabilidades por classe (validação)\n",
        "proba_df = pd.DataFrame(proba_val_lr, columns=[f'prob_{c}' for c in le.classes_])\n",
        "proba_df.plot(kind='hist', bins=30, alpha=0.6, figsize=(10,4))\n",
        "plt.title('Distribuição de probabilidades por classe (validação - LR)')\n",
        "plt.xlabel('Probabilidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OphO64iGDmw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribuição de rótulos previstos no teste (argmax)\n",
        "test_proba_df = pd.DataFrame(proba_test_lr, columns=[f'prob_{c}' for c in le.classes_])\n",
        "test_proba_df['pred_label'] = test_proba_df[[f'prob_{c}' for c in le.classes_]].idxmax(axis=1).apply(lambda s: s.replace('prob_',''))\n",
        "counts = test_proba_df['pred_label'].value_counts()\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=counts.index, y=counts.values, palette='muted')\n",
        "plt.title('Distribuição de rótulos previstos (teste - LR)')\n",
        "plt.xlabel('Rótulo previsto')\n",
        "plt.ylabel('Contagem')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e5n0Pll8DpXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálcular features parecidas"
      ],
      "metadata": {
        "id": "W3bv_wZhDvM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "tfidf_resp_a = TfidfVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
        "tfidf_resp_b = TfidfVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
        "\n",
        "\n",
        "tfidf_resp_a.fit(train_f['response_a'].astype(str).tolist())\n",
        "resp_a_tfidf_train = tfidf_resp_a.transform(train_f['response_a'].astype(str))\n",
        "resp_a_tfidf_test = tfidf_resp_a.transform(test_f['response_a'].astype(str))\n",
        "\n",
        "\n",
        "tfidf_resp_b.fit(train_f['response_b'].astype(str).tolist())\n",
        "resp_b_tfidf_train = tfidf_resp_b.transform(train_f['response_b'].astype(str))\n",
        "resp_b_tfidf_test = tfidf_resp_b.transform(test_f['response_b'].astype(str))\n",
        "\n",
        "\n",
        "svd_resp_a = TruncatedSVD(n_components=n_svd, random_state=42)\n",
        "svd_resp_b = TruncatedSVD(n_components=n_svd, random_state=42)\n",
        "\n",
        "#\n",
        "svd_resp_a.fit(resp_a_tfidf_train)\n",
        "resp_a_svd_train = svd_resp_a.transform(resp_a_tfidf_train)\n",
        "resp_a_svd_test = svd_resp_a.transform(resp_a_tfidf_test)\n",
        "\n",
        "#\n",
        "svd_resp_b.fit(resp_b_tfidf_train)\n",
        "resp_b_svd_train = svd_resp_b.transform(resp_b_tfidf_train)\n",
        "resp_b_svd_test = svd_resp_b.transform(resp_b_tfidf_test)\n",
        "\n",
        "# 8. CCalculo de coeficiente simiar\n",
        "def calculate_cosine_similarity(vec1, vec2):\n",
        "    norm1 = np.linalg.norm(vec1, axis=1)\n",
        "    norm2 = np.linalg.norm(vec2, axis=1)\n",
        "    denominator = norm1 * norm2\n",
        "    denominator[denominator == 0] = 1\n",
        "\n",
        "    similarity = np.sum(vec1 * vec2, axis=1) / denominator\n",
        "    similarity[norm1 == 0] = 0\n",
        "    similarity[norm2 == 0] = 0\n",
        "    return similarity\n",
        "\n",
        "sim_p_a_train = calculate_cosine_similarity(prompt_svd_train, resp_a_svd_train)\n",
        "sim_p_b_train = calculate_cosine_similarity(prompt_svd_train, resp_b_svd_train)\n",
        "sim_a_b_train = calculate_cosine_similarity(resp_a_svd_train, resp_b_svd_train)\n",
        "\n",
        "# 9. Calculate cosine similarity features for test_f\n",
        "sim_p_a_test = calculate_cosine_similarity(prompt_svd_test, resp_a_svd_test)\n",
        "sim_p_b_test = calculate_cosine_similarity(prompt_svd_test, resp_b_svd_test)\n",
        "sim_a_b_test = calculate_cosine_similarity(resp_a_svd_test, resp_b_svd_test)\n",
        "\n",
        "print(\"Shape of sim_p_a_train:\", sim_p_a_train.shape)\n",
        "print(\"Shape of sim_p_b_train:\", sim_p_b_train.shape)\n",
        "print(\"Shape of sim_a_b_train:\", sim_a_b_train.shape)\n",
        "print(\"Shape of sim_p_a_test:\", sim_p_a_test.shape)\n",
        "print(\"Shape of sim_p_b_test:\", sim_p_b_test.shape)\n",
        "print(\"Shape of sim_a_b_test:\", sim_a_b_test.shape)"
      ],
      "metadata": {
        "id": "n8N8yORWepBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar features numéricas e vetoriais\n",
        "num_cols = ['prompt_len','prompt_words','resp_a_len','resp_b_len','resp_a_words','resp_b_words','len_diff_ab','abs_len_diff_ab']\n",
        "X_num_train = train_f[num_cols].values\n",
        "X_num_test = test_f[num_cols].values\n",
        "X_train = np.hstack([X_num_train, prompt_svd_train, resp_svd_train])\n",
        "X_test = np.hstack([X_num_test, prompt_svd_test, resp_svd_test])\n",
        "print('X_train shape', X_train.shape)\n",
        "print('X_test shape', X_test.shape)"
      ],
      "metadata": {
        "id": "HhIiNOFjcCQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new = np.hstack([X_train, sim_p_a_train.reshape(-1, 1), sim_p_b_train.reshape(-1, 1), sim_a_b_train.reshape(-1, 1)])\n",
        "X_test_new = np.hstack([X_test, sim_p_a_test.reshape(-1, 1), sim_p_b_test.reshape(-1, 1), sim_a_b_test.reshape(-1, 1)])\n",
        "\n",
        "print('Shape of X_train_new:', X_train_new.shape)\n",
        "print('Shape of X_test_new:', X_test_new.shape)"
      ],
      "metadata": {
        "id": "xPVB1UgVeEoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_new, X_val_new, y_tr, y_val = train_test_split(X_train_new, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# treinando regressão com multiplas features\n",
        "lr_new = LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs')\n",
        "lr_new.fit(X_tr_new, y_tr)\n",
        "\n",
        "# Prevendo novos valores de log de perda com novos dados\n",
        "proba_val_lr_new = lr_new.predict_proba(X_val_new)\n",
        "ll_lr_new = log_loss(y_val, proba_val_lr_new)\n",
        "y_pred_lr_new = lr_new.predict(X_val_new)\n",
        "print('LogisticRegression (New Features) - Validation log loss:', ll_lr_new)\n",
        "print('Accuracy (val) (LR New Features):', accuracy_score(y_val, y_pred_lr_new))\n",
        "print(classification_report(y_val, y_pred_lr_new, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "Y8OD_XrMD9uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "conf_new = pd.crosstab(le.inverse_transform(y_val), le.inverse_transform(y_pred_lr_new))\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(conf_new, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matriz de confusão (LR com Novas Features - validação)')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xlabel('Previsto')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xcg_8wfVEBu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Rede Neural"
      ],
      "metadata": {
        "id": "Gob0r1NEEEqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#colocar as labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train_f['label'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_new)\n",
        "X_test_scaled = scaler.transform(X_test_new)\n",
        "\n",
        "y_one_hot = to_categorical(y)\n",
        "\n",
        "print('Shape of X_train_scaled:', X_train_scaled.shape)\n",
        "print('Shape of X_test_scaled:', X_test_scaled.shape)\n",
        "print('Shape of y_one_hot:', y_one_hot.shape)"
      ],
      "metadata": {
        "id": "2j5mSQsNcE8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "L8k9NVnCcR7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#compilar os dados\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled successfully with Adam optimizer, categorical_crossentropy loss, and accuracy metric.\")"
      ],
      "metadata": {
        "id": "FP8YfKJgcVJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinar e ver o valor de perda\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    y_one_hot,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Neural network training complete.\")"
      ],
      "metadata": {
        "id": "oiR8WRFIcXhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_nn, X_val_nn, y_tr_nn_one_hot, y_val_nn_one_hot = train_test_split(X_train_scaled, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot)\n",
        "\n",
        "y_val_nn = np.argmax(y_val_nn_one_hot, axis=1)\n",
        "\n",
        "proba_val_nn = model.predict(X_val_nn)\n",
        "\n",
        "y_pred_nn = np.argmax(proba_val_nn, axis=1)\n",
        "\n",
        "ll_nn = log_loss(y_val_nn_one_hot, proba_val_nn)\n",
        "\n",
        "accuracy_nn = accuracy_score(y_val_nn, y_pred_nn)\n",
        "\n",
        "print('Neural Network - Validation log loss:', ll_nn)\n",
        "print('Accuracy (val) (NN):', accuracy_nn)\n",
        "\n",
        "print('\\nClassification Report (NN Validation):')\n",
        "print(classification_report(y_val_nn, y_pred_nn, target_names=le.classes_))\n",
        "\n",
        "conf_nn = pd.crosstab(le.inverse_transform(y_val_nn), le.inverse_transform(y_pred_nn))\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(conf_nn, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Matriz de confusão (Neural Network - validação)')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xlabel('Previsto')\n",
        "plt.tight_layout()\n",
        "os.makedirs('figs_for_slides', exist_ok=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UfdsOY8bccvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizar a rede neural treinada para fazer previsões de probabilidade no conjunto de teste (X_test_scaled).\n",
        "proba_test_nn = model.predict(X_test_scaled)\n",
        "print('Shape of predicted probabilities for test set:', proba_test_nn.shape)"
      ],
      "metadata": {
        "id": "wOzpUMB9cfcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criar probabilidade das respostas\n",
        "df_proba_nn = pd.DataFrame(proba_test_nn, columns=[f'prob_{c}' for c in le.classes_])\n",
        "\n",
        "#mapear os itens\n",
        "map_cols = {'a':'winner_model_a','b':'winner_model_b','tie':'winner_model_tie'}\n",
        "\n",
        "#iniciar nova coluna id\n",
        "sub_nn = pd.DataFrame()\n",
        "sub_nn['id'] = test['id']\n",
        "\n",
        "#adicionar coluna de dataframe\n",
        "for cls in le.classes_:\n",
        "    sub_nn[map_cols[cls]] = df_proba_nn[f'prob_{cls}'].values\n",
        "\n",
        "#normalizar os itens\n",
        "sums_nn = sub_nn[['winner_model_a','winner_model_b','winner_model_tie']].sum(axis=1)\n",
        "sub_nn[['winner_model_a','winner_model_b','winner_model_tie']] = sub_nn[['winner_model_a','winner_model_b','winner_model_tie']].div(sums_nn, axis=0)\n",
        "print('submission_nn.csv salvo com shape', sub_nn.shape)\n",
        "sub_nn.head()"
      ],
      "metadata": {
        "id": "lwsbc2vach2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}